{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Science_Seminar2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15V-O0um5pWmR-AH_tHbDDMRacE1udjtT",
      "authorship_tag": "ABX9TyO1e1QkLYBhrjEGpyvnDPTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadr75/UK_gov_Twitter_Covid_data_analysis/blob/main/Data_Science_Seminar2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B3tMuVY5hw1"
      },
      "source": [
        "#Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGeQxG581hAR",
        "outputId": "a511444b-a414-42b3-f4f3-7872bceaa5c6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "## credentials contain:\n",
        "consumer_key        = \"5aKJhd985bBGzuTmd6ubtWYgA\"\n",
        "consumer_secret     = \"dPHCv1Noj0udVF646wrqBBnCW0eDibpf1LD3D8QDwx1E3MqZMC\"\n",
        "access_token        = \"1177062871-9bF1WqV2AS9fjXd5tY9xx0JV4j8xRj9q4I5KkPU\"\n",
        "access_token_secret = \"quH3ogy2PpRd5dOIro96eLGB3CSBirmjJZ3IniY9bmRfy\"\n",
        "\n",
        "import tweepy\n",
        "print(tweepy.__version__)\n",
        "\n",
        "# Authorize our Twitter credentials\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#Work directory\n",
        "Work_dir = \"/content/drive/MyDrive/DS UK gov/\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ji-gU1-5kxR"
      },
      "source": [
        "#Automated *Users* Seeking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5MQ5_I5gJl",
        "outputId": "7096df03-7e0d-41dd-e28d-757bfb953468"
      },
      "source": [
        "Tweet_id_file = open(Work_dir+\"TweetID_Gen_Auto.csv\", \"a\")\n",
        "current_file = open(Work_dir+\"TweetID_Gen_Auto.csv\", \"r\")\n",
        "First_time = False # Should be True for the first time search operation\n",
        "\n",
        "# List of potential keywords leading to official accounts of subject under scrutiny\n",
        "# transport, Health, NHS, gov, covid, corona, minister\n",
        "\n",
        "# List of locations\n",
        "# uk, wales, scotland, nothern-ireland, England, london, Birmingham, glasgow, liverpool, bristol, manchester, sheffield, leeds,\n",
        "\n",
        "# the query to be searched > a combination of location and keyword from above\n",
        "q = \"leeds health\"\n",
        "\n",
        "current_file.readline()\n",
        "id_lists = list()\n",
        "if First_time is False:\n",
        "  for item in current_file.readlines():\n",
        "    id_lists.append(int(item.split(', ')[2]))\n",
        "else:\n",
        "  Tweet_id_file.write(\"screen_name\" + \", \" + \"location\" + \", \" + \"id\" + \", \" + \"followers_count\" + \", \" + \"freinds_count\" + \", \" + \"favourites_count, Description\\n\")\n",
        "\n",
        "# search the query\n",
        "users = api.search_users(q, 200)\n",
        "\n",
        "# save user information of the users retrieved\n",
        "for user in users:\n",
        "    user_retreive = api.get_user(user.screen_name)\n",
        "    if user_retreive.verified == True: #Check whether the user is officially verified within tweeter\n",
        "        print(user_retreive.id)\n",
        "        if user_retreive.id not in id_lists:\n",
        "          Tweet_id_file.write(user.screen_name + \", \" + str(user_retreive.location.replace(\",\", \"-\")) + \", \" + str(user_retreive.id) + \", \" + str(user_retreive.followers_count) + \", \" + str(user_retreive.friends_count) + \", \" + str(user_retreive.favourites_count)+ \", \" + user_retreive.description.replace(\",\", \"-\").replace(\"\\n\", \"-\") + \"\\n\")\n",
        "        #print(user_retreive.screen_name)#ID \n",
        "\n",
        "Tweet_id_file.close()\n",
        "current_file.close()\n",
        "\n",
        "#Results are further cleaned and search for target accounts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "338260834\n",
            "58490193\n",
            "109237832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN7nKdyqYCl1"
      },
      "source": [
        "#User Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDCD3p4v6ifd"
      },
      "source": [
        "userID = \"NHSEnglandLDN\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgIIeONI62jD"
      },
      "source": [
        "tweets = api.user_timeline(screen_name=userID, \n",
        "                           # 200 is the maximum allowed count\n",
        "                           count=200,\n",
        "                           include_rts = False,\n",
        "                           # Necessary to keep full_text \n",
        "                           # otherwise only the first 140 words are extracted\n",
        "                           tweet_mode = 'extended'\n",
        "                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjWkQTDDQdIX"
      },
      "source": [
        "#Verified ID Parser:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbjpE_pCn46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7138d838-875e-4ca5-9688-592a9a0c7324"
      },
      "source": [
        "Tweet = api.get_user(userID)\n",
        "Tweet.id, Tweet.verified # Outputs the username and the whether it is verfied or not (using a tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31129844, True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIYsmHYd64vE",
        "outputId": "25459fcb-5d90-4a2b-ada5-bfb546550153"
      },
      "source": [
        "# Output information of a tweet\n",
        "for info in tweets[:1]:\n",
        "     print(\"ID: {}\".format(info.id))\n",
        "     print(info.created_at)\n",
        "     print(info.full_text)\n",
        "     print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID: 1429352707329077248\n",
            "2021-08-22 08:00:16\n",
            "Looking for somewhere to get your #COVIDVaccine in the capital today? üëÄüíâ\n",
            "\n",
            "Check your local area‚Äôs pop-up and walk-in vaccination sites  ‚û°Ô∏è https://t.co/NKzeK4mb01 https://t.co/vTOdkzlw9A\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RkyxZpqbv4U"
      },
      "source": [
        "#Extraction of information from specified user\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W431t3PkeSUw"
      },
      "source": [
        "def Tweet_extractor(userID):\n",
        "  tweets = api.user_timeline(screen_name=userID, \n",
        "                             # 200 is the maximum allowed count\n",
        "                             count=200,\n",
        "                             include_rts = False,\n",
        "                             # Necessary to keep full_text \n",
        "                             # otherwise only the first 140 words are extracted\n",
        "                             tweet_mode = 'extended'\n",
        "                             )\n",
        "  all_tweets = []\n",
        "  all_tweets.extend(tweets)\n",
        "  oldest_id = tweets[-1].id\n",
        "  while True:\n",
        "    tweets = api.user_timeline(screen_name=userID, \n",
        "                               # 200 is the maximum allowed count\n",
        "                               count=200,\n",
        "                               include_rts = False,\n",
        "                               max_id = oldest_id - 1,\n",
        "                               # Necessary to keep full_text \n",
        "                               # otherwise only the first 140 words are extracted\n",
        "                               tweet_mode = 'extended'\n",
        "                               )\n",
        "    if len(tweets) == 0:\n",
        "      break\n",
        "    oldest_id = tweets[-1].id\n",
        "    all_tweets.extend(tweets)\n",
        "    print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
        "\n",
        "  outtweets = [[tweet.id_str, \n",
        "                tweet.created_at, \n",
        "                tweet.favorite_count, \n",
        "                tweet.retweet_count, \n",
        "                tweet.full_text.encode(\"utf-8\").decode(\"utf-8\")] \n",
        "              for idx,tweet in enumerate(all_tweets)]\n",
        "  return outtweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "C67xji0-7SGk",
        "outputId": "3749ae5d-0880-4f3d-d0ef-54f09174c61e"
      },
      "source": [
        "# Please enter your desired user id\n",
        "userID = \"matthancock\"\n",
        "\n",
        "outtweets = Tweet_extractor(userID)\n",
        "\n",
        "# Creation of dataframe object and saving the file in work directory\n",
        "df = DataFrame(outtweets,columns=[\"id\",\"created_at\",\"favorite_count\",\"retweet_count\", \"text\"]) \n",
        "df.to_csv('%s_tweets.csv' % userID,index=False)\n",
        "df.head(3)\n",
        "!cp /content/matthancock_tweets.csv /content/drive/MyDrive/DS\\ UK\\ gov/DA_Raw_DB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N of tweets downloaded till now 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1372115555692462082</td>\n",
              "      <td>2021-03-17 09:20:15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@master_deutsche ÿÆŸäŸÑŸä ŸÑÿ∑ŸÅ ÿØÿßÿ±Ÿäÿå ÿß⁄ØŸá ÿ®ÿ±ÿßŸÖ ÿ®ŸÅÿ±ÿ≥ÿ™...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1371883513926983683</td>\n",
              "      <td>2021-03-16 17:58:12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Can anyone send me #clubhouseinvite?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1367038428475498497</td>\n",
              "      <td>2021-03-03 09:05:34</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@Mariaaaaa_R üòÇüòÇüëåüëå</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...                                               text\n",
              "0  1372115555692462082  ...  @master_deutsche ÿÆŸäŸÑŸä ŸÑÿ∑ŸÅ ÿØÿßÿ±Ÿäÿå ÿß⁄ØŸá ÿ®ÿ±ÿßŸÖ ÿ®ŸÅÿ±ÿ≥ÿ™...\n",
              "1  1371883513926983683  ...               Can anyone send me #clubhouseinvite?\n",
              "2  1367038428475498497  ...                                  @Mariaaaaa_R üòÇüòÇüëåüëå\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8iINa1ZiZVH"
      },
      "source": [
        "#Check existance of Covid related subject\n",
        "\n",
        "---\n",
        "Also importance of the account under the investigation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaF-pIYRhepG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ada081a-e7ff-4e2e-ee2f-d02c8153a297"
      },
      "source": [
        "# Take out the text column from the dataset and count the quantities of covid word repeated\n",
        "x_l = df['text']\n",
        "cnt = 0\n",
        "for item in x_l:\n",
        "  if \"covid\" in item or \"corona\" in item:\n",
        "    if '#' in item:\n",
        "      cnt += 1\n",
        "#print out this quantity\n",
        "print(cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjGUVHbKyFT"
      },
      "source": [
        "# Plot the number of favorites and retweets overal in the account\n",
        "ylabels = [\"favorite_count\",\"retweet_count\"]\n",
        "\n",
        "fig = plt.figure(figsize=(13,3))\n",
        "fig.subplots_adjust(hspace=0.01,wspace=0.01)\n",
        "\n",
        "n_row = len(ylabels)\n",
        "n_col = 1\n",
        "for count, ylabel in enumerate(ylabels):\n",
        "    ax = fig.add_subplot(n_row,n_col,count+1)\n",
        "    ax.plot(df[\"created_at\"],df[ylabel])\n",
        "    ax.set_ylabel(ylabel)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWoLFMnKyd_"
      },
      "source": [
        "# specified tweets with more than some thresholds of favorites and retweets\n",
        "df_sub = df.loc[(df[\"favorite_count\"] > 400) & (df[\"retweet_count\"] > 20),:]\n",
        "for irow in range(df_sub.shape[0]):\n",
        "    df_row = df_sub.iloc[irow,:]\n",
        "    \n",
        "    print(df_row[\"created_at\"])\n",
        "    print(\"favorite_count={:6} retweet_count={:6}\".format(df_row[\"favorite_count\"],df_row[\"retweet_count\"]))\n",
        "    print(df_row[\"text\"])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8DV_zb6GKC"
      },
      "source": [
        "page = 1\n",
        "while True:\n",
        "  statuses = api.user_timeline(screen_name=userID)\n",
        "  if statuses:\n",
        "    for status in statuses:\n",
        "      # process status here\n",
        "      print(status)\n",
        "      #process_status(status)\n",
        "  else:\n",
        "    # All done\n",
        "    break\n",
        "  page += 1  # next page"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QBNy5w2aS6-"
      },
      "source": [
        "# Extract all hashtags in dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMYBhm7ponYt"
      },
      "source": [
        "Generates a DB from tweets their ID plus the Hashtags used in total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVkwYWHaXEB"
      },
      "source": [
        "# specify the database name\n",
        "data_dir = Work_dir + \"DA_Raw_DB\"\n",
        "\n",
        "filter_chars = [';', ':', '!', \"*\", \")\", \"-\", \"\\n\", \"\\\\\", \"|\", \".\", \":\", \"?\", \";\", \",\", \"@\", \"$\", \"%\", \"^\", \"*\", \"(\", \"~\"]\n",
        "\n",
        "Full_gathered_data = list()\n",
        "\n",
        "for name in os.listdir(data_dir):\n",
        "  if name.endswith(\".csv\"):\n",
        "    filee = pd.read_csv(data_dir + \"/\" + name)\n",
        "    Hashtag_list = list()\n",
        "    Valid_date_list = list()\n",
        "    for i in range(filee.shape[0]):\n",
        "      Year = int(filee['created_at'][i][:4])\n",
        "      Month = int(filee['created_at'][i][5:7])\n",
        "      Day = int(filee['created_at'][i][8:10])\n",
        "      if Year == 2020 and Month > 1 and Day > 2:\n",
        "        Valid_date_list.append(i)\n",
        "      if Year == 2021:\n",
        "          #print(\"{}.{}.{}\".format(Year,Month,Day))\n",
        "          if Month < 5:\n",
        "            Valid_date_list.append(i)\n",
        "    for item in Valid_date_list:\n",
        "      tweet_text = filee['text'][item]\n",
        "      if \"#\" in tweet_text:\n",
        "        splitted_text = tweet_text.split(\"#\")\n",
        "        Mined_hashtag = \"\"\n",
        "        for i in range(1,len(splitted_text)):\n",
        "          Mined_hashtag = splitted_text[i].split(\" \")[0]\n",
        "          for it in filter_chars:\n",
        "            Mined_hashtag = Mined_hashtag.split(it)[0]\n",
        "          Hashtag_list.append(Mined_hashtag)\n",
        "    Full_gathered_data.append([name.split(\"_tweets\")[0],Hashtag_list])\n",
        "dff = pd.DataFrame(Full_gathered_data, columns = ['User_name', 'Hashtags'])\n",
        "# dff contains all the hashtags of each account"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wooaM9qTohzV"
      },
      "source": [
        "Hashtag DB with counting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-bp5X5OhQfE"
      },
      "source": [
        "# having a dictionary object used to count the quantities of each hashtag being repeated\n",
        "Counter_dict = {}\n",
        "for item in dff['Hashtags']:\n",
        "  for each in item:\n",
        "    if each not in Counter_dict:\n",
        "      Counter_dict[each] = 1\n",
        "    else:\n",
        "      Counter_dict[each] = Counter_dict[each] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edonpaMXkzAN"
      },
      "source": [
        "# save the results as a dataset in the specified directory, with a threshold of being 10 times repeated\n",
        "Hashtag_Final_Count = list()\n",
        "for item in Counter_dict:\n",
        "  if Counter_dict[item] > 10:\n",
        "    Hashtag_Final_Count.append([item,Counter_dict[item]])\n",
        "Hashtag_cnt_data = pd.DataFrame(Hashtag_Final_Count, columns = ['Hashtag_name', 'Count'])\n",
        "Hashtag_cnt_data = Hashtag_cnt_data.sort_values(by=['Count'],ascending=False)\n",
        "Hashtag_cnt_data.to_csv(work_dir + 'Raw_Hashtags_plus_relative_classification/Mined_Hashtag_cnt_02022020_31042021.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3aN0De1KxVDT",
        "outputId": "7e0cff75-cfb8-45fc-fd88-c29e1a523892"
      },
      "source": [
        "Hashtag_cnt_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hashtag_name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COVID19</td>\n",
              "      <td>5125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>coronavirus</td>\n",
              "      <td>3092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>HouseofLords</td>\n",
              "      <td>1247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>StayHomeSaveLives</td>\n",
              "      <td>567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>SettlementScheme</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NHSCOVIDVaccine</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Ambulance</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>ScotBudget</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>hiring</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Hashtag_name  Count\n",
              "3             COVID19   5125\n",
              "6         coronavirus   3092\n",
              "52       HouseofLords   1247\n",
              "31        Coronavirus    636\n",
              "34  StayHomeSaveLives    567\n",
              "..                ...    ...\n",
              "69   SettlementScheme     52\n",
              "36    NHSCOVIDVaccine     52\n",
              "40          Ambulance     52\n",
              "73         ScotBudget     51\n",
              "55             hiring     51\n",
              "\n",
              "[98 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IokPfx2W5phN"
      },
      "source": [
        "# Extract based on key words and hashtags\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "After the analysis we created several datasets based on the hashtags that were repeated more and our specified keywords.\n",
        "\n",
        "The results form two datasets which are used in our project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tElamcPijHHz"
      },
      "source": [
        "def Search_based_on_hashtags_keywords(input_list, data_dir, dff_type=True):\n",
        "  if dff_type is True:\n",
        "    dff = pd.DataFrame(columns = ['User_name', 'Hashtag', 'id', 'created_at', 'favorite_count', 'retweet_count', 'text'])\n",
        "  else:\n",
        "    dff = pd.DataFrame(columns = ['User_name', 'Hashtag', 'id', 'created_at'])\n",
        "  Full_gathered_data = list()\n",
        "  cnter = 0\n",
        "  List_per_keyword = list()\n",
        "  Arr_hld = np.array((7,), dtype=str)\n",
        "  for name in os.listdir(data_dir):\n",
        "    if name.endswith(\".csv\"):\n",
        "      filee = pd.read_csv(data_dir + \"/\" + name)\n",
        "      Hashtag_list = list()\n",
        "      Valid_date_list = list()\n",
        "      for i in range(filee.shape[0]):\n",
        "        Year = int(filee['created_at'][i][:4])\n",
        "        Month = int(filee['created_at'][i][5:7])\n",
        "        Day = int(filee['created_at'][i][8:10])\n",
        "        if Year == 2020:\n",
        "          if Month == 2 and Day > 2:\n",
        "            Valid_date_list.append(i)\n",
        "          elif Month > 2:\n",
        "            Valid_date_list.append(i)\n",
        "        if Year == 2021:\n",
        "            if Month < 5:\n",
        "              Valid_date_list.append(i)\n",
        "      for item in Valid_date_list:\n",
        "        tweet_text = filee['text'][item]\n",
        "        for key_w in Hashtags_under_search:\n",
        "          for it in tweet_text.split(\" \"):\n",
        "            if key_w == it:\n",
        "              if dff_type is True:\n",
        "                dat = name.split(\"_tweets\")[0], key_w.split(\"#\")[1], filee['id'][item],\tfilee['created_at'][item], filee['favorite_count'][item],\tfilee['retweet_count'][item],\tfilee['text'][item]\n",
        "              else:\n",
        "                dat = name.split(\"_tweets\")[0], key_w, filee['id'][item],\tfilee['created_at'][item]\n",
        "              dff.loc[cnter] = dat\n",
        "              cnter += 1\n",
        "  return dff\n",
        "\n",
        "# the function takes the list and workspace raw db dir to produce a dataset based on our search items (which can be keywords or hashtags)\n",
        "# dff_type shows the structure in which we want to have the output dataset\n",
        "data_dir = Work_dir + \"DA_Raw_DB\"\n",
        "\n",
        "Hashtags_under_search = ['#COVID19', '#coronavirus', '#HouseofLords', '#Coronavirus', \n",
        "                         '#StayHomeSaveLives', '#LordsQs', '#KeepWalesSafe', \n",
        "                         '#COVID„Éº19', '#StayAlert', '#OurNHSPeople', '#Covid19', \n",
        "                         '#PMQs', '#HelpUsHelpYou', '#vaccine', '#COVIDVaccine', \n",
        "                         '#ThankYouNHS', '#EveryMindMatters', '#HereForYou', \n",
        "                         '#COVID', '#NHS', '#ClinicalResearch', '#BackToSchoolSafely', \n",
        "                         '#TravelSafely', '#LetsTalkLoneliness', '#flu', \n",
        "                         '#CovidVaccine', '#HandsFaceSpace', '#HowAreYouDoing', '#YouAreNotAlone', \n",
        "                         '#EnjoySummerSafely', '#covid19', '#ResearchVsCovid', \n",
        "                         '#OxfordVaccine', '#MentalHealth', '#howareyoudoing', \n",
        "                         '#WelshQs', '#WorkingSafely', '#StayHome', \n",
        "                         '#StayAtHome', '#FMQs', '#InThisTogether', '#PHEHealthMatters', \n",
        "                         '#ICYMI', '#StaySafe', '#YellowCard', '#WeAreScotland', \n",
        "                         '#RECOVERYtrial', '#COVID19LessonsLearnt', \n",
        "                         '#PriorityCovidResearch', '#NHSCOVIDVaccine', \n",
        "                         '#VaccinesWork', '#BePartofResearch', '#mentalhealth', \n",
        "                         '#PublicHealth', '#BuildBackBetter', \n",
        "                         '#WorldMentalHealthDay', \"#SafeOnline\", \"#vaccines\"]\n",
        "\n",
        "dff = Search_based_on_hashtags_keywords(data_dir, Hashtags_under_search)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amw2RF3ZFxo6"
      },
      "source": [
        "# save the dataset in our desired location\n",
        "dff.to_csv('/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Hashtags_per_user_plusinfo_02022020_31042021.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r2nntFPMbkQ"
      },
      "source": [
        "# Time relative to keyword or hashtag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yeO0lM1g2kP"
      },
      "source": [
        "Hashtags_under_search = ['#COVID19', '#coronavirus', '#HouseofLords', '#Coronavirus', \n",
        "                         '#StayHomeSaveLives', '#LordsQs', '#KeepWalesSafe', \n",
        "                         '#COVID„Éº19', '#StayAlert', '#OurNHSPeople', '#Covid19', \n",
        "                         '#PMQs', '#HelpUsHelpYou', '#vaccine', '#COVIDVaccine', \n",
        "                         '#ThankYouNHS', '#EveryMindMatters', '#HereForYou', \n",
        "                         '#COVID', '#NHS', '#ClinicalResearch', '#BackToSchoolSafely', \n",
        "                         '#TravelSafely', '#LetsTalkLoneliness', '#flu', \n",
        "                         '#CovidVaccine', '#HandsFaceSpace', '#HowAreYouDoing', '#YouAreNotAlone', \n",
        "                         '#EnjoySummerSafely', '#covid19', '#ResearchVsCovid', \n",
        "                         '#OxfordVaccine', '#MentalHealth', '#howareyoudoing', \n",
        "                         '#WelshQs', '#WorkingSafely', '#StayHome', \n",
        "                         '#StayAtHome', '#FMQs', '#InThisTogether', '#PHEHealthMatters', \n",
        "                         '#ICYMI', '#StaySafe', '#YellowCard', '#WeAreScotland', \n",
        "                         '#RECOVERYtrial', '#COVID19LessonsLearnt', \n",
        "                         '#PriorityCovidResearch', '#NHSCOVIDVaccine', \n",
        "                         '#VaccinesWork', '#BePartofResearch', '#mentalhealth', \n",
        "                         '#PublicHealth', '#BuildBackBetter', \n",
        "                         '#WorldMentalHealthDay', \"#SafeOnline\", \"#vaccines\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYfe_fBMleq"
      },
      "source": [
        "# data_dir =\"/content/drive/MyDrive/DS UK gov/DA_Raw_DB\"\n",
        "\n",
        "# Hashtags_under_search = ['#vaccine', '#COVIDVaccine', '#CovidVaccine', \n",
        "#                          '#OxfordVaccine', '#NHSCOVIDVaccine', \n",
        "#                          '#VaccinesWork', '#vaccines']\n",
        "# #Hashtags_under_search = ['Vaccine', 'vaccine', 'Vaccination', 'vaccination', 'vaccinated', 'coronavaccine', 'covidvaccine',\n",
        "# #                         'immunization', 'immunisation', 'immunize', 'immunise']\n",
        "# dff = pd.DataFrame(columns = ['User_name', 'Hashtag', 'id', 'created_at'])\n",
        "# Full_gathered_data = list()\n",
        "# cnter = 0\n",
        "# List_per_keyword = list()\n",
        "# Arr_hld = np.array((7,), dtype=str)\n",
        "# for name in os.listdir(data_dir):\n",
        "#   if name.endswith(\".csv\"):\n",
        "#     filee = pd.read_csv(data_dir + \"/\" + name)\n",
        "#     Hashtag_list = list()\n",
        "#     Valid_date_list = list()\n",
        "#     for i in range(filee.shape[0]):\n",
        "#       Year = int(filee['created_at'][i][:4])\n",
        "#       Month = int(filee['created_at'][i][5:7])\n",
        "#       Day = int(filee['created_at'][i][8:10])\n",
        "#       if Year == 2020:\n",
        "#         if Month == 2 and Day > 2:\n",
        "#           Valid_date_list.append(i)\n",
        "#         elif Month > 2:\n",
        "#           Valid_date_list.append(i)\n",
        "#       if Year == 2021:\n",
        "#           if Month < 5:\n",
        "#             Valid_date_list.append(i)\n",
        "#     for item in Valid_date_list:\n",
        "#       tweet_text = filee['text'][item]\n",
        "#       for key_w in Hashtags_under_search:\n",
        "#         for it in tweet_text.split(\" \"):\n",
        "#           if key_w == it:\n",
        "#             dat = name.split(\"_tweets\")[0], key_w.split(\"#\")[1], filee['id'][item],\tfilee['created_at'][item], filee['favorite_count'][item],\tfilee['retweet_count'][item],\tfilee['text'][item]\n",
        "#             dff.loc[cnter] = dat\n",
        "#             cnter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQ8b5ZzJK3E"
      },
      "source": [
        "# dff.to_csv('/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Vaccination_Hashtags_for_user_plustime_02022020_31042021.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usJj0CWdPfgC"
      },
      "source": [
        "# data_dir =\"/content/drive/MyDrive/DS UK gov/DA_Raw_DB\"\n",
        "\n",
        "# Hashtags_under_search = ['#COVID19', '#coronavirus', '#HouseofLords', '#Coronavirus', \n",
        "#                          '#StayHomeSaveLives', '#LordsQs', '#KeepWalesSafe', \n",
        "#                          '#COVID„Éº19', '#StayAlert', '#OurNHSPeople', '#Covid19', \n",
        "#                          '#PMQs', '#HelpUsHelpYou', '#vaccine', '#COVIDVaccine', \n",
        "#                          '#ThankYouNHS', '#EveryMindMatters', '#HereForYou', \n",
        "#                          '#COVID', '#NHS', '#ClinicalResearch', '#BackToSchoolSafely', \n",
        "#                          '#TravelSafely', '#LetsTalkLoneliness', '#flu', \n",
        "#                          '#CovidVaccine', '#HandsFaceSpace', '#HowAreYouDoing', '#YouAreNotAlone', \n",
        "#                          '#EnjoySummerSafely', '#covid19', '#ResearchVsCovid', \n",
        "#                          '#OxfordVaccine', '#MentalHealth', '#howareyoudoing', \n",
        "#                          '#WelshQs', '#WorkingSafely', '#StayHome', \n",
        "#                          '#StayAtHome', '#FMQs', '#InThisTogether', '#PHEHealthMatters', \n",
        "#                          '#ICYMI', '#StaySafe', '#YellowCard', '#WeAreScotland', \n",
        "#                          '#RECOVERYtrial', '#COVID19LessonsLearnt', \n",
        "#                          '#PriorityCovidResearch', '#NHSCOVIDVaccine', \n",
        "#                          '#VaccinesWork', '#BePartofResearch', '#mentalhealth', \n",
        "#                          '#PublicHealth', '#BuildBackBetter', \n",
        "#                          '#WorldMentalHealthDay', \"#SafeOnline\", \"#vaccines\"]\n",
        "# dff = pd.DataFrame(columns = ['User_name', 'Hashtag', 'id', 'created_at'])\n",
        "# Full_gathered_data = list()\n",
        "# cnter = 0\n",
        "# List_per_keyword = list()\n",
        "# Arr_hld = np.array((7,), dtype=str)\n",
        "# for name in os.listdir(data_dir):\n",
        "#   if name.endswith(\".csv\"):\n",
        "#     filee = pd.read_csv(data_dir + \"/\" + name)\n",
        "#     Hashtag_list = list()\n",
        "#     Valid_date_list = list()\n",
        "#     for i in range(filee.shape[0]):\n",
        "#       Year = int(filee['created_at'][i][:4])\n",
        "#       Month = int(filee['created_at'][i][5:7])\n",
        "#       Day = int(filee['created_at'][i][8:10])\n",
        "#       if Year == 2020:\n",
        "#         if Month == 2 and Day > 2:\n",
        "#           Valid_date_list.append(i)\n",
        "#         elif Month > 2:\n",
        "#           Valid_date_list.append(i)\n",
        "#       if Year == 2021:\n",
        "#           #print(\"{}.{}.{}\".format(Year,Month,Day))\n",
        "#           if Month < 5:\n",
        "#             Valid_date_list.append(i)\n",
        "#     for item in Valid_date_list:\n",
        "#       tweet_text = filee['text'][item]\n",
        "#       for key_w in Hashtags_under_search:\n",
        "#         for it in tweet_text.split(\" \"):\n",
        "#           if key_w == it:\n",
        "#             dat = name.split(\"_tweets\")[0], key_w, filee['id'][item],\tfilee['created_at'][item]\n",
        "#             dff.loc[cnter] = dat\n",
        "#             cnter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "jZHFiMqPPI_v",
        "outputId": "0b1a3e0d-35a2-4502-bd9f-9d82486a5475"
      },
      "source": [
        "dff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_name</th>\n",
              "      <th>Hashtag</th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>#NHS</td>\n",
              "      <td>1388229167708217348</td>\n",
              "      <td>2021-04-30 20:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>#COVID19</td>\n",
              "      <td>1388168772863856641</td>\n",
              "      <td>2021-04-30 16:30:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>#COVID19</td>\n",
              "      <td>1388148854332313604</td>\n",
              "      <td>2021-04-30 15:10:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>#COVID19</td>\n",
              "      <td>1388115927464431620</td>\n",
              "      <td>2021-04-30 13:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>#COVID19</td>\n",
              "      <td>1388044198687870976</td>\n",
              "      <td>2021-04-30 08:15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11708</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>#coronavirus</td>\n",
              "      <td>1228635061576065024</td>\n",
              "      <td>2020-02-15 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>#coronavirus</td>\n",
              "      <td>1228408569021648896</td>\n",
              "      <td>2020-02-14 20:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11710</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>#coronavirus</td>\n",
              "      <td>1228345872854982656</td>\n",
              "      <td>2020-02-14 15:50:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11711</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>#COVID</td>\n",
              "      <td>1227593198681255939</td>\n",
              "      <td>2020-02-12 14:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11712</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>#Coronavirus</td>\n",
              "      <td>1225841304170618881</td>\n",
              "      <td>2020-02-07 17:58:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11713 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            User_name       Hashtag                   id           created_at\n",
              "0           DHSCgovuk          #NHS  1388229167708217348  2021-04-30 20:30:00\n",
              "1           DHSCgovuk      #COVID19  1388168772863856641  2021-04-30 16:30:01\n",
              "2           DHSCgovuk      #COVID19  1388148854332313604  2021-04-30 15:10:52\n",
              "3           DHSCgovuk      #COVID19  1388115927464431620  2021-04-30 13:00:01\n",
              "4           DHSCgovuk      #COVID19  1388044198687870976  2021-04-30 08:15:00\n",
              "...               ...           ...                  ...                  ...\n",
              "11708  publichealthni  #coronavirus  1228635061576065024  2020-02-15 11:00:00\n",
              "11709  publichealthni  #coronavirus  1228408569021648896  2020-02-14 20:00:00\n",
              "11710  publichealthni  #coronavirus  1228345872854982656  2020-02-14 15:50:52\n",
              "11711  publichealthni        #COVID  1227593198681255939  2020-02-12 14:00:00\n",
              "11712  publichealthni  #Coronavirus  1225841304170618881  2020-02-07 17:58:36\n",
              "\n",
              "[11713 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhJIh17iWrpc"
      },
      "source": [
        "Time object plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8_6v4GQelK"
      },
      "source": [
        "import matplotlib\n",
        "from datetime import datetime\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LltTXp0lv9de"
      },
      "source": [
        "sorted_dff_peraccount = dff.sort_values(by=['User_name'],ascending=False) #sort by user name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0tJE3VswH_Q"
      },
      "source": [
        "## cnt_idx > keeps total number of tweets tweeted from various accounts  \n",
        "## list_user_notrepeated > keeps dictionary of accounts mapping into numbers corresponding to each account\n",
        "ID_Cnt = 0\n",
        "cnt = 0\n",
        "list_user_notrepeated = {}\n",
        "for i in range(len(sorted_dff_peraccount)): \n",
        "  if sorted_dff_peraccount['User_name'][i] not in list_user_notrepeated:\n",
        "    list_user_notrepeated[sorted_dff_peraccount['User_name'][i]] = cnt\n",
        "    cnt += 1\n",
        "Array_hld = np.chararray((cnt,4*365), itemsize=10, unicode=True)\n",
        "cnt_idx = np.zeros((cnt+1), dtype=int)\n",
        "id_list = list()\n",
        "for i in range(len(sorted_dff_peraccount)):\n",
        "  # following if checks if the tweet is already added in another hashtag\n",
        "  if sorted_dff_peraccount['id'][i] not in id_list:\n",
        "    id_list.append(sorted_dff_peraccount['id'][i])\n",
        "    ID_Cnt = list_user_notrepeated[sorted_dff_peraccount['User_name'][i]]\n",
        "    Array_hld[ID_Cnt][cnt_idx[ID_Cnt]] = sorted_dff_peraccount['created_at'][i]\n",
        "    cnt_idx[ID_Cnt] += 1\n",
        "\n",
        "# output > Array_hld which consists dates of various tweets for cnt_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fWsf9991MZr"
      },
      "source": [
        "Dates_per_number_dict = {}\n",
        "for i in range(len(cnt_idx)):\n",
        "  for j in range(cnt_idx[i]):\n",
        "    if Array_hld[i][j] not in Dates_per_number_dict:\n",
        "      Dates_per_number_dict[Array_hld[i][j]] = 1\n",
        "    else:\n",
        "      Dates_per_number_dict[Array_hld[i][j]] = Dates_per_number_dict[Array_hld[i][j]] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hC4DIpL5cQ_"
      },
      "source": [
        "datetime_obj = list()\n",
        "values_list = list()\n",
        "for item in Dates_per_number_dict:\n",
        "  # Sometimes one day springs so we can do sth like this and define a threshold\n",
        "  if Dates_per_number_dict[item] < 800:\n",
        "    values_list.append(Dates_per_number_dict[item])\n",
        "    datetime_obj.append(datetime.strptime(item, '%Y-%m-%d'))\n",
        "  else:\n",
        "    values_list.append(100)\n",
        "    datetime_obj.append(datetime.strptime(item, '%Y-%m-%d'))\n",
        "# Preperation of data based on hashtags and time objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8Gjf32flOm"
      },
      "source": [
        "# datetime_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDxKYxHqr7x2"
      },
      "source": [
        "# dff.to_csv('/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Vaccination_Hashtags_for_user_plustime_02022020_31042021.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFnl5tfK2_UH"
      },
      "source": [
        "Making a new dataset for hashtags per time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9651LkNsTt4"
      },
      "source": [
        "\n",
        "dff = pd.DataFrame(columns = ['Time', 'Hashtags'])\n",
        "Full_gathered_data = list()\n",
        "cnter = 0\n",
        "List_per_keyword = list()\n",
        "Arr_hld = np.array((7,), dtype=str)\n",
        "for item in Dates_per_number_dict:\n",
        "  dff.loc[cnter] = (datetime.strptime(item, '%Y-%m-%d'), Dates_per_number_dict[item])\n",
        "  cnter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MswveEhe3DOH"
      },
      "source": [
        "Making two datasets for Covid death and new cases daily based on time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3oX6oUGnLLs"
      },
      "source": [
        "Our_reference_dataset = ['/content/drive/MyDrive/DS UK gov/COVID statistics /Covid_death_rates.csv',\n",
        "                         '/content/drive/MyDrive/DS UK gov/COVID statistics /Covid_new_cases.csv']\n",
        "\n",
        "cnter = 0\n",
        "dff_death_rates = pd.DataFrame(columns = ['Time', 'Deat_per_day'])\n",
        "with open(Our_reference_dataset[0], 'r', newline='') as csvfile: #Define the location in the list to desired dataset\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)\n",
        "  for row in datareader:\n",
        "    dff_death_rates.loc[cnter] = (datetime.strptime(row[0], '%m/%d/%Y'), row[1])\n",
        "    cnter += 1\n",
        "\n",
        "# The output would be a dataset of real-world data per time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "pbeTq_gltyON",
        "outputId": "2a993561-76aa-4be8-e72f-b374458d9aa1"
      },
      "source": [
        "# 1. outer join on time between both datasets\n",
        "# 2. sort per time\n",
        "# 3. save the dataset with desired name\n",
        "\n",
        "dff_hashtags_death = pd.concat([dff.set_index('Time'),dff_death_rates.set_index('Time')], axis=1, join='outer')\n",
        "dff_hashtags_death = dff_hashtags_death.sort_values(by=['Time'],ascending=True)\n",
        "dff_hashtags_death.to_csv('/content/drive/MyDrive/DS UK gov/Relative_Diagrams/Hashtags_Death_ratio1.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Deat_per_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-29</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-28</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-04-27</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-04-26</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Time Deat_per_day\n",
              "0   2021-04-30            8\n",
              "1   2021-04-29           13\n",
              "2   2021-04-28           14\n",
              "3   2021-04-27           12\n",
              "4   2021-04-26           11\n",
              "..         ...          ...\n",
              "420 2020-03-06            0\n",
              "421 2020-03-05            3\n",
              "422 2020-03-04            0\n",
              "423 2020-03-03            2\n",
              "424 2020-03-02            1\n",
              "\n",
              "[425 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgzJslMwpfni"
      },
      "source": [
        "# dff_hashtags_death = pd.concat([dff.set_index('Time'),dff_death_rates.set_index('Time')], axis=1, join='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "3A-O2bMqsrIY",
        "outputId": "521608e1-0f3f-4723-d6dc-51b9da288487"
      },
      "source": [
        "# pd.concat([dff.set_index('Time'),dff_death_rates.set_index('Time')], axis=1, join='outer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Deat_per_day</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-02-03</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-04</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-06</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-07</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-26</th>\n",
              "      <td>33</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-27</th>\n",
              "      <td>39</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-28</th>\n",
              "      <td>46</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-29</th>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-30</th>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Hashtags Deat_per_day\n",
              "Time                            \n",
              "2020-02-03        5          NaN\n",
              "2020-02-04        3          NaN\n",
              "2020-02-05        7          NaN\n",
              "2020-02-06        4          NaN\n",
              "2020-02-07        4          NaN\n",
              "...             ...          ...\n",
              "2021-04-26       33           11\n",
              "2021-04-27       39           12\n",
              "2021-04-28       46           14\n",
              "2021-04-29       36           13\n",
              "2021-04-30       26            8\n",
              "\n",
              "[452 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jtkCDrQaY4H"
      },
      "source": [
        "# dff_hashtags_death = dff_hashtags_death.sort_values(by=['Time'],ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AajITMNaUS3"
      },
      "source": [
        "# dff_hashtags_death.to_csv('/content/drive/MyDrive/DS UK gov/Relative_Diagrams/Hashtags_Death_ratio1.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGREfWOPrn3N"
      },
      "source": [
        "# dff_hashtags_death.to_csv('/content/drive/MyDrive/DS UK gov/Relative_Diagrams/Hashtags_NewCase_ratio.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "XziW5tUeuf0M",
        "outputId": "56d53a64-a22a-4454-8693-5169ea6b9451"
      },
      "source": [
        "# dff.sort_values(by=['Time'],ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-29</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-28</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-04-27</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-04-26</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>2020-02-06</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>2020-02-05</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>2020-02-04</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>2020-02-03</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>433 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Time Hashtags\n",
              "0   2021-04-30       26\n",
              "1   2021-04-29       36\n",
              "2   2021-04-28       46\n",
              "3   2021-04-27       39\n",
              "4   2021-04-26       33\n",
              "..         ...      ...\n",
              "408 2020-02-07        4\n",
              "392 2020-02-06        4\n",
              "406 2020-02-05        7\n",
              "428 2020-02-04        3\n",
              "404 2020-02-03        5\n",
              "\n",
              "[433 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpn0IXIsskQK"
      },
      "source": [
        "# dff.to_csv('/content/drive/MyDrive/Hashtags_per_day.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzadZ1CBrlt2"
      },
      "source": [
        "Dates_per_number_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prr--MlS52D7"
      },
      "source": [
        "Plot a high quality image of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0yCBXX8ZK2"
      },
      "source": [
        "from matplotlib.dates import DateFormatter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wruoGgZUNxXq"
      },
      "source": [
        "def Plot_image(datetime_obj,values_list, title_g=\"\",Date_format=\"%Y-%m\", dpi=800, save_enable = True):\n",
        "  fig, ax = plt.subplots(figsize=(20, 8))\n",
        "\n",
        "  # Add x-axis and y-axis\n",
        "  ax.plot(datetime_obj,values_list,\n",
        "        color='purple')\n",
        "\n",
        "  # Set title and labels for axes\n",
        "  ax.set(xlabel=\"Date\",\n",
        "        ylabel=\"Tweets Count\",\n",
        "        title=title_g)\n",
        "\n",
        "  # Define the date format\n",
        "  date_form = DateFormatter(Date_format)\n",
        "  ax.xaxis.set_major_formatter(date_form)\n",
        "  if save_enable is True:\n",
        "    plt.savefig(\"/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Vaccination_keywords_per_month.png\",dpi=800)\n",
        "  plt.show()\n",
        "\n",
        "title_g = [\"Daily Tweets Related to Covid Feb 2020 - May 2021 Across all accounts\",\n",
        "           \"Daily Vaccination Related Tweets Feb 2020 - May 2021\"]\n",
        "\n",
        "Plot_image(datetime_obj,values_list, title_g=title_g[0], save_enable = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vmHC-PDw7QS0",
        "outputId": "141e9839-bda4-432e-d0b9-130059e8a54b"
      },
      "source": [
        "# dates = matplotlib.dates.date2num(datetime_obj)\n",
        "# matplotlib.pyplot.plot_date(dates, values_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8d39549090>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEPgHEKw8zEi"
      },
      "source": [
        "# c = 0\n",
        "# for item in values_list:\n",
        "#   if item > c:\n",
        "#     c = item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBEKsDgx8529",
        "outputId": "7e9b3d93-28da-466f-dbb6-9b71ca35844a"
      },
      "source": [
        "# datetime_obj.append(datetime.strptime(item, '%Y-%m-%d'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGyLypi27tBg"
      },
      "source": [
        "# fig, ax = plt.subplots(figsize=(20, 8))\n",
        "\n",
        "# # Add x-axis and y-axis\n",
        "# ax.bar(datetime_obj,values_list,\n",
        "#        color='purple')\n",
        "\n",
        "# # Set title and labels for axes\n",
        "# ax.set(xlabel=\"Date\",\n",
        "#        ylabel=\"Tweets Count\",\n",
        "#        title=\"Daily Vaccination Related Tweets Feb 2019 - May 2021\")\n",
        "\n",
        "# # Define the date format\n",
        "# date_form = DateFormatter(\"%Y-%m\")\n",
        "# ax.xaxis.set_major_formatter(date_form)\n",
        "# plt.savefig(\"/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Vaccination_keywords_per_month.png\",dpi=800)\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX6USssSCj0i"
      },
      "source": [
        "# fig, ax = plt.subplots(figsize=(20, 8))\n",
        "\n",
        "# # Add x-axis and y-axis\n",
        "# ax.bar(datetime_obj,values_list,\n",
        "#        color='blue')\n",
        "\n",
        "# # Set title and labels for axes\n",
        "# ax.set(xlabel=\"Date\",\n",
        "#        ylabel=\"Total Tweets Count\",\n",
        "#        title=\"Daily Tweets Related to Covid Feb 2020 - May 2021 Across all accounts\")\n",
        "\n",
        "# # Define the date format\n",
        "# date_form = DateFormatter(\"%Y-%m\")\n",
        "# ax.xaxis.set_major_formatter(date_form)\n",
        "# plt.savefig(\"/content/drive/MyDrive/DS UK gov/Raw_Hashtags_plus_relative_classification/Tweet_per_month.png\",dpi=800)\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDoQWISg6Zrb"
      },
      "source": [
        "values_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ExvjzMTQk2b"
      },
      "source": [
        "# sorted_dff_pertime = dff.sort_values(by=['created_at'],ascending=False)\n",
        "# datetime_object = list()\n",
        "# for i in range(len(dff)):\n",
        "#   datetime_object.append(datetime.strptime(sorted_dff_pertime['created_at'][i], '%Y-%m-%d %H:%M:%S'))\n",
        "# for \n",
        "# #dates = matplotlib.dates.date2num(datetime_object)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMZBTFMzVW_s"
      },
      "source": [
        "# cnt = 0\n",
        "# for item in datetime_object:\n",
        "#   if item.year == 2020:\n",
        "#     for co in range(1,13):\n",
        "#       if item.month == co:\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERIpDgfvfw6s"
      },
      "source": [
        "#EXtracting Retweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_7JmZlRWnLT"
      },
      "source": [
        "Vaccinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRrQo4Eb_BIx"
      },
      "source": [
        "import csv\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApMPPx7BdaAv"
      },
      "source": [
        "def Extract_retweets(DB_path, Out_DB_path, Wait_rate = True, Limit = 100)#Pasrses at most 100 retweets into output database (Wait_rate should be true to parse retweets with api limitation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwAd6oqEqe3d"
      },
      "source": [
        "def Extract_retweets(DB_path, Out_DB_path, Wait_rate = True, Limit = 100):#Pasrses at most 100 retweets into output database (Wait_rate should be true to parse retweets with api limitation)\n",
        "  # Authorize our Twitter credentials\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "  api = tweepy.API(auth)\n",
        "  api = tweepy.API(auth, wait_on_rate_limit=Wait_rate)\n",
        "\n",
        "  db_file = open(Data_dir, 'r')\n",
        "  db_file.readline()\n",
        "  id_name_lists = list()\n",
        "  user_names_list = list()\n",
        "  for item in db_file.readlines():\n",
        "    splt = item.split(',')[2]\n",
        "    if splt not in id_name_lists:\n",
        "      id_name_lists.append(splt)\n",
        "      user_names_list.append(item.split(',')[0])\n",
        "  print(\"User list length {}\".format(len(user_names_list)))\n",
        "  with open(Out_DB_path, 'a', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    #spamwriter.writerow([\"User_name\", \"ID\", \"List_of_retweets\"])\n",
        "    for i, ID in enumerate(id_name_lists):\n",
        "      if i > 421: # in case of an interruption this can be increased so u can begin from the middle of the dataset where the parsing was performed lately by just seeting i more than the desired value\n",
        "        # the ID of the tweet\n",
        "        # number to retweets to be retrieved\n",
        "        count = Limit\n",
        "        # getting the retweeters\n",
        "        retweets_list = api.retweets(int(ID), count)\n",
        "        #print(len(retweets_list))\n",
        "        # printing the screen names of the retweeters\n",
        "        user_names = list()\n",
        "        user_names.append(user_names_list[i])\n",
        "        user_names.append(ID)\n",
        "        for retweet in retweets_list:\n",
        "          user_names.append(retweet.user.screen_name)\n",
        "        spamwriter.writerow(user_names)\n",
        "        # print out i counting to set in case of interruption\n",
        "        sys.stdout.write(\"\\r\" + \"#samples written: {}\".format(i))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "#  For hashtags retweets\n",
        "Data_dir = '/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Vaccination_Hashtags_for_user_plustime_02022020_31042021.csv'\n",
        "Out_DB_path = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Vaccination_Hashtags.csv'\n",
        "Extract_retweets(data_dir, Out_DB_path)\n",
        "\n",
        "# For Vaccination keywords retweets\n",
        "Data_dir = '/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Hashtags_per_user_plusinfo_02022020_31042021.csv'\n",
        "Out_DB_path = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Covid_Hashtags.csv'\n",
        "Extract_retweets(data_dir, Out_DB_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMV-40dSVZ-C",
        "outputId": "4c7242e5-bc01-47da-c847-05e254483084"
      },
      "source": [
        "# import pandas as pd\n",
        "# import csv\n",
        "# import sys\n",
        "\n",
        "# Data_dir = '/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Hashtags_per_user_plusinfo_02022020_31042021.csv'\n",
        "# pd_df = pd.read_csv(Data_dir)\n",
        "# # Authorize our Twitter credentials\n",
        "# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# auth.set_access_token(access_token, access_token_secret)\n",
        "# api = tweepy.API(auth)\n",
        "# api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "# id_name_lists = list()\n",
        "# user_names_list = list()\n",
        "# for it in range(len(pd_df['id'])):\n",
        "#   splt = pd_df['id'][it]\n",
        "#   if splt not in id_name_lists:\n",
        "#     id_name_lists.append(splt)\n",
        "#     user_names_list.append(pd_df['User_name'][it])\n",
        "# print(\"User list length {}\".format(len(user_names_list)))\n",
        "# with open('/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Covid_Hashtags.csv', 'a', newline='') as csvfile:\n",
        "#   spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "#                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "#   #spamwriter.writerow([\"User_name\", \"ID\", \"List_of_retweets\"])\n",
        "#   for i, ID in enumerate(id_name_lists):\n",
        "#     if i > 10570:#6619:\n",
        "#       # the ID of the tweet\n",
        "#       # number to retweets to be retrieved\n",
        "#       count = 100\n",
        "#       # getting the retweeters\n",
        "#       retweets_list = api.retweets(int(ID), count)\n",
        "#       #print(len(retweets_list))\n",
        "#       # printing the screen names of the retweeters\n",
        "#       user_names = list()\n",
        "#       user_names.append(user_names_list[i])\n",
        "#       user_names.append(ID)\n",
        "#       for retweet in retweets_list:\n",
        "#         user_names.append(retweet.user.screen_name)\n",
        "#       spamwriter.writerow(user_names)\n",
        "#       sys.stdout.write(\"\\r\" + \"#samples written: {}\".format(i))\n",
        "#       sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User list length 10571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSj2LDDmdM-6"
      },
      "source": [
        "Cleaning Databases\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-8e3I8dY_h"
      },
      "source": [
        "# import pandas as pd\n",
        "# import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isi9oAz4dMW3"
      },
      "source": [
        "# Creating a dataset with an attribute of list of retweets and saving it in csv format\n",
        "\n",
        "id_lists = list()\n",
        "Data_file = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Covid_Hashtags.csv'\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  with open('/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Covid_Hashtags_cleaned.csv', 'w', newline='') as csvfile1:\n",
        "    spamwriter = csv.writer(csvfile1, delimiter=',',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    spamwriter.writerow([\"User_name\", \"ID\", \"List_of_retweets\"])\n",
        "    for row in datareader:      \n",
        "      user_names = list()\n",
        "      if row[1] not in id_lists:\n",
        "        id_lists.append(row[1])\n",
        "        for retweet in row:\n",
        "          user_names.append(retweet)\n",
        "        spamwriter.writerow(user_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA-J6lC7dc7Y"
      },
      "source": [
        "# We need a list of our specified accounts and their names so:\n",
        "# list_names is the name of our specified gov accounts in our former datasets\n",
        "\n",
        "Data_dir = '/content/drive/MyDrive/DS UK gov/Specified_hashtag_n_keyword_search/Hashtags_per_user_plusinfo_02022020_31042021.csv'\n",
        "#Hashtags_per_user_plusinfo_02022020_31042021\n",
        "#Vaccination_Hashtags_for_user_plustime_02022020_31042021\n",
        "#Vaccination_Keywords_for_user_plustime_02022020_31042021\n",
        "pd_df = pd.read_csv(Data_dir)\n",
        "list_names = list()\n",
        "time_list = list()\n",
        "cnter=0\n",
        "for name in pd_df['User_name']:\n",
        "  if name not in list_names:\n",
        "    list_names.append(name)\n",
        "  cnter += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "HnjVHLC-nI4F",
        "outputId": "b04d80d0-8b18-49fd-c343-d284732beb31"
      },
      "source": [
        "# pd_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_name</th>\n",
              "      <th>Hashtag</th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>1388229167708217348</td>\n",
              "      <td>2021-04-30 20:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>Vaccine</td>\n",
              "      <td>1388195194122670081</td>\n",
              "      <td>2021-04-30 18:15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1388148854332313604</td>\n",
              "      <td>2021-04-30 15:10:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1388115927464431620</td>\n",
              "      <td>2021-04-30 13:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DHSCgovuk</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>1388115927464431620</td>\n",
              "      <td>2021-04-30 13:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6202</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1291328168100425729</td>\n",
              "      <td>2020-08-06 11:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6203</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1290603386320990209</td>\n",
              "      <td>2020-08-04 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6204</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1286254734030987264</td>\n",
              "      <td>2020-07-23 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6205</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>1285167386623172608</td>\n",
              "      <td>2020-07-20 10:59:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6206</th>\n",
              "      <td>publichealthni</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>1255503263723655168</td>\n",
              "      <td>2020-04-29 14:24:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6207 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           User_name      Hashtag                   id           created_at\n",
              "0          DHSCgovuk  vaccination  1388229167708217348  2021-04-30 20:30:00\n",
              "1          DHSCgovuk      Vaccine  1388195194122670081  2021-04-30 18:15:00\n",
              "2          DHSCgovuk      vaccine  1388148854332313604  2021-04-30 15:10:52\n",
              "3          DHSCgovuk      vaccine  1388115927464431620  2021-04-30 13:00:01\n",
              "4          DHSCgovuk  vaccination  1388115927464431620  2021-04-30 13:00:01\n",
              "...              ...          ...                  ...                  ...\n",
              "6202  publichealthni      vaccine  1291328168100425729  2020-08-06 11:00:01\n",
              "6203  publichealthni      vaccine  1290603386320990209  2020-08-04 11:00:00\n",
              "6204  publichealthni      vaccine  1286254734030987264  2020-07-23 11:00:00\n",
              "6205  publichealthni      vaccine  1285167386623172608  2020-07-20 10:59:16\n",
              "6206  publichealthni  vaccination  1255503263723655168  2020-04-29 14:24:38\n",
              "\n",
              "[6207 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aeu_1KJ5lSDX"
      },
      "source": [
        "# Creating a dictionary based on id and creation time properties of our former datasets\n",
        "\n",
        "dict_id_time = {}\n",
        "for cnt in range(len(pd_df)):\n",
        "  dict_id_time[pd_df['id'][cnt]] = pd_df['created_at'][cnt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZpS5bQhIuj"
      },
      "source": [
        "# We check if there are\n",
        "# 1. Any self retweets > Remove them\n",
        "# 2. If it is retweeted from accounts specified within the gov > Keep them\n",
        "# e.g. \"Retweets_related_2_Covid_Hashtags_specified\" is our fully cleaned dataset\n",
        "\n",
        "Data_file = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_related_2_Covid_Hashtags_cleaned.csv'\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  with open('/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_from_specified_accounts/Retweets_related_2_Covid_Hashtags_specified.csv', 'w', newline='') as csvfile1:\n",
        "    spamwriter = csv.writer(csvfile1, delimiter=',',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    spamwriter.writerow([\"User_name\", \"ID\", \"Tweet_time\",\"List_of_specified_retweets\"])  \n",
        "    for row in datareader:\n",
        "      gonna_write = list()\n",
        "      gonna_write.append(row[0])\n",
        "      gonna_write.append(row[1])\n",
        "      try:\n",
        "        gonna_write.append(dict_id_time[int(row[1])])\n",
        "      except:\n",
        "        print(row)\n",
        "        break\n",
        "      list_retweeters = row[2:]\n",
        "      lets_write = False\n",
        "      for each in list_retweeters:\n",
        "        if each in list_names:\n",
        "          if each != row[0]:\n",
        "            lets_write = True\n",
        "            gonna_write.append(each)\n",
        "      if lets_write is True:\n",
        "        spamwriter.writerow(gonna_write)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYMuBcfQGbpM"
      },
      "source": [
        "#Counting retweets from the dataset\n",
        "\n",
        "In here, we want to have the quantity of data (which can be retweet data) per month granularity shown in a dataset.\n",
        "\n",
        "So, first we specify the users and then we will extract and sum up the countings on our data per month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQXPF8V4Fkb1"
      },
      "source": [
        "# import pandas as pd\n",
        "# import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsfSH_-pSodR"
      },
      "source": [
        "# name dict is further used to have our specified user names under investigation\n",
        "\n",
        "name_dict = list()\n",
        "Data_file = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_from_specified_accounts/Retweets_related_2_Covid_Hashtags_specified.csv'\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  for row in datareader:\n",
        "    name_list = row[0]\n",
        "    #for item in name_list:\n",
        "    if name_list not in name_dict:\n",
        "      name_dict.append(name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K4KzO3WTHqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cde738-44f3-4a99-956e-5e71e1694beb"
      },
      "source": [
        "name_dict # our specified usernames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DHSCgovuk',\n",
              " 'PHE_uk',\n",
              " 'NHSEngland',\n",
              " 'CommonsHealth',\n",
              " 'nadhimzahawi',\n",
              " 'MattHancock',\n",
              " 'UKParliament',\n",
              " 'HouseofCommons',\n",
              " 'UKHouseofLords',\n",
              " 'BorisJohnson',\n",
              " '10DowningStreet',\n",
              " 'UKGovScotland',\n",
              " 'scotgov',\n",
              " 'scotgovhealth',\n",
              " 'nidirect',\n",
              " 'healthdpt',\n",
              " 'fmwales',\n",
              " 'UKGovWales',\n",
              " 'WelshGovernment',\n",
              " 'PublicHealthW',\n",
              " 'NHSResearchScot',\n",
              " 'P_H_S_Official',\n",
              " 'GenomicsEngland',\n",
              " 'NIHRresearch',\n",
              " 'JimBethell',\n",
              " 'UKCivilService',\n",
              " 'transportgovuk',\n",
              " 'educationgovuk',\n",
              " 'mhclg',\n",
              " 'beisgovuk',\n",
              " 'DCMS',\n",
              " 'DWP',\n",
              " 'MHRAgovuk',\n",
              " 'publichealthni']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PpoysDTTWW3"
      },
      "source": [
        "# Creating a dictionary based on dates per available months which is going to hold the quantities of data repition per account in each month\n",
        "\n",
        "headings = list()\n",
        "headings.append(\"User name\")\n",
        "date_dict = {}\n",
        "Data_file = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_from_specified_accounts/Retweets_related_2_Covid_Hashtags_specified.csv'\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  for row in datareader:\n",
        "    name_list = row[2][:7]\n",
        "    if name_list not in date_dict:\n",
        "      date_dict[name_list] = 0\n",
        "      headings.append(name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkx4ocuUTqrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2401808d-3168-4248-e5e2-0c2e1d312393"
      },
      "source": [
        "date_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2020-02': 0,\n",
              " '2020-03': 0,\n",
              " '2020-04': 0,\n",
              " '2020-05': 0,\n",
              " '2020-06': 0,\n",
              " '2020-07': 0,\n",
              " '2020-08': 0,\n",
              " '2020-09': 0,\n",
              " '2020-10': 0,\n",
              " '2020-11': 0,\n",
              " '2020-12': 0,\n",
              " '2021-01': 0,\n",
              " '2021-02': 0,\n",
              " '2021-03': 0,\n",
              " '2021-04': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feYAZ-XjRJoa"
      },
      "source": [
        "def Retweet_count_pertime(DB_file, Out_DB_file, name_dict, date_dict):#Makes a dictionary from our specified accounts and outputs a db quantities of retweet on each tweet per month\n",
        "  drid_lists = list()\n",
        "  date_list = list()\n",
        "  \n",
        "  with open(Out_DB_file, 'w', newline='') as csvfile1:\n",
        "    spamwriter = csv.writer(csvfile1, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)  \n",
        "    spamwriter.writerow(headings)\n",
        "    for item1 in name_dict:\n",
        "      with open(DB_file, 'r', newline='') as csvfile:\n",
        "        datareader = csv.reader(csvfile)\n",
        "        next(datareader)  # yield the header row\n",
        "        print(item1)\n",
        "        for row in datareader: \n",
        "          if item1 == row[0]:\n",
        "            print(row)\n",
        "            date_dict[row[2][:7]] = date_dict[row[2][:7]] + len(row[3:])\n",
        "      print(date_dict, item1)\n",
        "      write_list = list()\n",
        "      write_list.append(item1)\n",
        "      for item in headings[1:]:\n",
        "        write_list.append(date_dict[item])\n",
        "        date_dict[item] = 0\n",
        "      spamwriter.writerow(write_list)\n",
        "\n",
        "\n",
        "Data_file = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_from_specified_accounts/Retweets_related_2_Covid_Hashtags_specified.csv'\n",
        "Out_ds = '/content/drive/MyDrive/DS UK gov/Retweets_data/Retweets_from_specified_accounts/3_Analysis_automated.csv'\n",
        "Retweet_count_pertime(Data_file, Out_ds, name_dict, date_dict) # Produces the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xh4poJd2AAm"
      },
      "source": [
        "# Couting Hashtags per account per month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVzBSlQZ2D3q"
      },
      "source": [
        "name_dict = list()\n",
        "Data_file = '/content/drive/MyDrive/Hashtags_per_user_plusinfo_02022020_31042021.csv'\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  for row in datareader:\n",
        "    name_list = row[0]\n",
        "    #for item in name_list:\n",
        "    if name_list not in name_dict:\n",
        "      name_dict.append(name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAsqIRhK2EKA"
      },
      "source": [
        "headings = list()\n",
        "headings.append(\"User name\")\n",
        "date_dict = {}\n",
        "with open(Data_file, 'r', newline='') as csvfile:\n",
        "  datareader = csv.reader(csvfile)\n",
        "  next(datareader)  # yield the header row\n",
        "  for row in datareader:\n",
        "    name_list = row[3][:7]\n",
        "    if name_list not in date_dict:\n",
        "      date_dict[name_list] = 0\n",
        "      headings.append(name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sixyq9Y2FNR"
      },
      "source": [
        "id_lists = list()\n",
        "date_list = list()\n",
        "\n",
        "with open('/content/drive/MyDrive/Hashtag_permonth_automated.csv', 'w', newline='') as csvfile1:\n",
        "  spamwriter = csv.writer(csvfile1, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)  \n",
        "  spamwriter.writerow(headings)\n",
        "  for item1 in name_dict:\n",
        "    with open(Data_file, 'r', newline='') as csvfile:\n",
        "      datareader = csv.reader(csvfile)\n",
        "      next(datareader)  # yield the header row\n",
        "      print(item1)\n",
        "      for row in datareader: \n",
        "        if item1 == row[0]:\n",
        "          print(row)\n",
        "          date_dict[row[3][:7]] = date_dict[row[3][:7]] + 1\n",
        "    print(date_dict, item1)\n",
        "    write_list = list()\n",
        "    write_list.append(item1)\n",
        "    for item in headings[1:]:\n",
        "      write_list.append(date_dict[item])\n",
        "      date_dict[item] = 0\n",
        "    spamwriter.writerow(write_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdJvKr9qoqaZ"
      },
      "source": [
        "# *Others*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zgQMCD2_CuI"
      },
      "source": [
        "Image Extraction of DB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNHC5bwZqgoO"
      },
      "source": [
        "# install the needed package for image download from twitter\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLsQktkGqiF4"
      },
      "source": [
        "import wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubaeOj2b5RZA"
      },
      "source": [
        "# Extract all images from a list of accounts specified for covid related data\n",
        "db_file = open(work_dir + \"TweetID_Gen_Auto.csv\", \"r\")  \n",
        "db_file.readline()\n",
        "id_name_lists = list()\n",
        "for item in db_file.readlines():\n",
        "  id_name_lists.append(item.split(', ')[0])\n",
        "#pull tweets from specific user. In userID, just put the page's username\n",
        "for idd_nm in id_name_lists:\n",
        "  while True:\n",
        "    tweets = api.user_timeline(screen_name=idd_nm, \n",
        "                           # 200 is the maximum allowed count\n",
        "                           count=200,\n",
        "                           include_rts = False,\n",
        "                           max_id = oldest_id - 1,\n",
        "                           # Necessary to keep full_text \n",
        "                           # otherwise only the first 140 words are extracted\n",
        "                           tweet_mode = 'extended'\n",
        "                           )\n",
        "    \n",
        "    if len(tweets) == 0:\n",
        "        break\n",
        "    media_files = set()\n",
        "    for status in tweets:\n",
        "      media = status.entities.get('media', [])\n",
        "      if(len(media) > 0):\n",
        "        media_files.add(media[0]['media_url'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        for media in tweet.entities.get(\"media\",[{}]):\n",
        "            #checks if there is any media-entity\n",
        "            if media.get(\"type\",None) == \"photo\":\n",
        "                # checks if the entity is of the type \"photo\"\n",
        "                # save to file etc.\n",
        "                wget.download(media[\"media_url\"],out=\"/content/down1/\")\n",
        "                #download(image_content, \"/content/ukk\")\n",
        "    oldest_id = tweets[-1].id\n",
        "    all_tweets.extend(tweets)\n",
        "    print('N of tweets downloaded till now {}'.format(len(all_tweets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0SzECftIjlf"
      },
      "source": [
        "# directory in which we will save the images\n",
        "!mkdir /content/down1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8FsQm3uR0Jl"
      },
      "source": [
        "# Extract all images from an account specified for covid related data\n",
        "acc_nam = \"itsFlo\"\n",
        "\n",
        "all_tweets = []\n",
        "# Authorize our Twitter credentials\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "#oldest_id = tweets[-1].id\n",
        "while True:\n",
        "    tweets = api.user_timeline(screen_name=acc_nam, \n",
        "                           # 200 is the maximum allowed count\n",
        "                           count=200,\n",
        "                           include_rts = False,\n",
        "                           max_id = oldest_id - 1,\n",
        "                           # Necessary to keep full_text \n",
        "                           # otherwise only the first 140 words are extracted\n",
        "                           tweet_mode = 'extended'\n",
        "                           )\n",
        "    \n",
        "    if len(tweets) == 0:\n",
        "        break\n",
        "    media_files = set()\n",
        "    for status in tweets:\n",
        "      media = status.entities.get('media', [])\n",
        "      if(len(media) > 0):\n",
        "        media_files.add(media[0]['media_url'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        for media in tweet.entities.get(\"media\",[{}]):\n",
        "            #checks if there is any media-entity\n",
        "            if media.get(\"type\",None) == \"photo\":\n",
        "                # checks if the entity is of the type \"photo\"\n",
        "                # save to file etc.\n",
        "                wget.download(media[\"media_url\"],out=\"/content/down1/\")\n",
        "                #download(image_content, \"/content/ukk\")\n",
        "    oldest_id = tweets[-1].id\n",
        "    all_tweets.extend(tweets)\n",
        "    print('N of tweets downloaded till now {}'.format(len(all_tweets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXEMRJFIrCkf"
      },
      "source": [
        "current trend in twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWKzltwGK0VW",
        "outputId": "eb82cda2-2e22-4f6d-8156-3f2aaf661362"
      },
      "source": [
        "#Python Trend Retreival - Current Tweets\n",
        "# -*- coding: utf-8 -*-\n",
        "import sys\n",
        "import tweepy\n",
        "import json\n",
        "\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Where On Earth ID for Brazil is 23424768.\n",
        "BRAZIL_WOE_ID = 44418\n",
        "\n",
        "brazil_trends = api.trends_place(BRAZIL_WOE_ID)\n",
        "\n",
        "trends = json.loads(json.dumps(brazil_trends, indent=1))\n",
        "\n",
        "for trend in trends[0][\"trends\"]:\n",
        "\t#print (trend[\"name\"]).strip(\"#\")\n",
        "  print(trend['name'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Santander\n",
            "#Wembley\n",
            "MATCH DAY\n",
            "Heidi\n",
            "poots\n",
            "George Square\n",
            "Essex\n",
            "#FACupFinal\n",
            "#HerGameToo\n",
            "#Caturday\n",
            "Matthew Parris\n",
            "Lenny Henry\n",
            "Tinie Tempah\n",
            "Travellers\n",
            "Lavazza\n",
            "Ibrox\n",
            "SAGE\n",
            "Koch\n",
            "Jamesy\n",
            "The Times\n",
            "Royal British Legion\n",
            "Debenhams\n",
            "GAME DAY\n",
            "Burnley v Leeds\n",
            "Bowen\n",
            "Kennedy\n",
            "Up the Chels\n",
            "Foxes\n",
            "Happy Birthday Theo\n",
            "Priti Patel in ¬£20m PPE\n",
            "New Jack\n",
            "Leicester City\n",
            "1st XI\n",
            "Knockout\n",
            "Bangladesh\n",
            "Pablo\n",
            "Armed Forces\n",
            "2nd XI\n",
            "Nish Kumar\n",
            "Raph\n",
            "Palace Pier\n",
            "West Suffolk Hospital\n",
            "Jim Davidson\n",
            "Ramsey\n",
            "Turf Moor\n",
            "Endwalker\n",
            "Ministerial Code\n",
            "Zhurong\n",
            "Heathrow\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}